{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670105e8-aa76-4b54-b2f0-bc1a8213e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7230473-56c6-413e-b6d8-cf0ff2524747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for input and output folder\n",
    "input_folder = 'data/rawData'\n",
    "output_folder = 'data/preprocessedData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec991bd-df8f-4845-b7df-a0c72606af1b",
   "metadata": {},
   "source": [
    "Displaying first few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f151c-70d7-4772-94b8-3eb5d2d0a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(input_folder)\n",
    "\n",
    "# Filter for common image file extensions\n",
    "image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "image_files = [f for f in files if f.lower().endswith(image_extensions)]\n",
    "\n",
    "# Sort the image files to ensure consistent order\n",
    "image_files.sort()\n",
    "\n",
    "# Display the first few images\n",
    "num_images_to_display = 5 \n",
    "for i, image_file in enumerate(image_files[:num_images_to_display]):\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    try:\n",
    "        img = mpimg.imread(image_path)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Image {i+1}: {image_file}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {image_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1dda19-300a-469e-9810-456e46170d26",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f154ac-0fa0-40c1-b2d5-200e5827ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the file names to an appropriate format\n",
    "def rename_files(directory):\n",
    "    existing_filenames = set()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        # Normalize the filename to ASCII\n",
    "        normalized_filename = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode('ascii')\n",
    "        # Replace spaces with underscores and remove special characters\n",
    "        sanitized_filename = ''.join(c if c.isalnum() or c in (' ', '.', '_') else '_' for c in normalized_filename)\n",
    "        # Replace spaces with underscores\n",
    "        sanitized_filename = sanitized_filename.replace(' ', '_')\n",
    "\n",
    "        # Ensure the filename is unique within the directory\n",
    "        original_sanitized_filename = sanitized_filename\n",
    "        counter = 1\n",
    "        while sanitized_filename in existing_filenames or os.path.exists(os.path.join(directory, sanitized_filename)):\n",
    "            name, ext = os.path.splitext(original_sanitized_filename)\n",
    "            sanitized_filename = f\"{name}_{counter}{ext}\"\n",
    "            counter += 1\n",
    "\n",
    "        existing_filenames.add(sanitized_filename)\n",
    "\n",
    "        old_path = os.path.join(directory, filename)\n",
    "        new_path = os.path.join(directory, sanitized_filename)\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f'Renamed: {old_path} -> {new_path}')\n",
    "\n",
    "input_folder = 'data/rawData' \n",
    "rename_files(input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a2332-7f91-463f-b5ff-e05e14a9171c",
   "metadata": {},
   "source": [
    "Resize and remove noise from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb042c-4d5e-4653-af88-ad2e31293046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through images in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construct the full path to the image\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Check if the image was loaded successfully\n",
    "        if img is not None:\n",
    "            # Resize image to 256x256\n",
    "            img_resized = cv2.resize(img, (256, 256))\n",
    "            \n",
    "            # Apply Gaussian blur for noise reduction\n",
    "            img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)\n",
    "            \n",
    "            # Save the preprocessed image\n",
    "            cv2.imwrite(os.path.join(output_folder, filename), img_denoised)\n",
    "        else:\n",
    "            print(f\"Warning: Unable to load image {img_path}. It may be corrupted or in an unsupported format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e43e21-765e-4cc5-9a12-9ad700fdfdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53495716-2217-4196-ac64-b9fa26d9297e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7517c-73ed-473a-bad9-0526756187bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a021a-33dc-4545-89a9-43a7a25a04a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb4bbc-e4d2-45ff-9e68-33d672f014eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab01618-e73f-461b-9fc7-eec8e9de975a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88cffd-62fd-44aa-9dec-bd718be880e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f65a8-6666-4c4d-904f-5f28ec6fb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# from torch.utils.data import Dataset\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# class UnlabeledImageDataset(Dataset):\n",
    "#     def __init__(self, image_dir, transform=None):\n",
    "#         self.image_dir = image_dir\n",
    "#         # self.image_paths = [\n",
    "#             os.path.join(image_dir, fname)\n",
    "#             for fname in os.listdir(image_dir)\n",
    "#             if fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "#         ]\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.image_paths[idx]\n",
    "#         image = Image.open(img_path).convert('RGB')\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image\n",
    "\n",
    "# # Parameters\n",
    "# dataroot = \"data/preprocessedData\"\n",
    "# batch_size = 128\n",
    "# image_size = 64\n",
    "# workers = 2\n",
    "\n",
    "# # Transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(image_size),\n",
    "#     transforms.CenterCrop(image_size),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (0.5,)),\n",
    "# ])\n",
    "\n",
    "# # Dataset and DataLoader\n",
    "# dataset = UnlabeledImageDataset(dataroot, transform=transform)\n",
    "# # dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a3873-6796-41dc-ab64-09edfb0df7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Generator Model\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, nz, ngf, nc):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 8),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 4),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 2),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ngf),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.main(input)\n",
    "\n",
    "# # Discriminator Model\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, nc, ndf):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 2),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 4),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(ndf * 8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         return self.main(input).view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859610a-2da7-4acd-be20-a93d8fc2e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# # Hyperparameters\n",
    "# nz = 100       # Latent vector size\n",
    "# ngf = 64       # Generator feature maps\n",
    "# ndf = 64       # Discriminator feature maps\n",
    "# nc = 3         # Number of channels in the images (RGB)\n",
    "# lr = 0.0002    # Learning rate\n",
    "# beta1 = 0.5    # Beta1 for Adam optimizer\n",
    "# batch_size = 128\n",
    "# image_size = 64\n",
    "# num_epochs = 5\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Initialize the models\n",
    "# netG = Generator(nz, ngf, nc).to(device)\n",
    "# netD = Discriminator(nc, ndf).to(device)\n",
    "\n",
    "# # Initialize weights\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Conv') != -1:\n",
    "#         m.weight.data.normal_(0.0, 0.02)\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         m.weight.data.normal_(1.0, 0.02)\n",
    "#         m.bias.data.fill_(0)\n",
    "# netG.apply(weights_init)\n",
    "# netD.apply(weights_init)\n",
    "\n",
    "# # Setup Adam optimizers\n",
    "# optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# # Loss function\n",
    "# criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ffc0e-71b8-4bf1-9756-ec4e73d877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.utils as vutils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Fixed noise for generating consistent images during training\n",
    "# fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# # Training the GAN\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i, data in enumerate(dataloader, 0):\n",
    "#         ############################\n",
    "#         # (1) Update D network\n",
    "#         ###########################\n",
    "#         netD.zero_grad()\n",
    "#         real_images = data.to(device)\n",
    "#         b_size = real_images.size(0)\n",
    "#         label = torch.full((b_size,), 1., dtype=torch.float, device=device)\n",
    "#         output = netD(real_images)\n",
    "#         errD_real = criterion(output, label)\n",
    "#         errD_real.backward()\n",
    "#         D_x = output.mean().item()\n",
    "\n",
    "#         # Generate fake images\n",
    "#         noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "#         fake_images = netG(noise)\n",
    "#         label.fill_(0.)\n",
    "#         output = netD(fake_images.detach())  # Corrected: 'fake' changed to 'fake_images' and added closing parenthesis\n",
    "#         errD_fake = criterion(output, label)\n",
    "#         errD_fake.backward()\n",
    "#         D_G_z1 = output.mean().item()\n",
    "#         errD = errD_real + errD_fake\n",
    "#         optimizerD.step()\n",
    "\n",
    "#         # (2) Update G network\n",
    "#         ###########################\n",
    "#         netG.zero_grad()\n",
    "#         label.fill_(1.)  # Fake labels are real for generator cost\n",
    "#         output = netD(fake_images)\n",
    "#         errG = criterion(output, label)\n",
    "#         errG.backward()\n",
    "#         D_G_z2 = output.mean().item()\n",
    "#         optimizerG.step()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729037e-057b-4be3-be4b-a7cf1e50ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# from torchvision.utils import save_image\n",
    "\n",
    "# # Ensure the output directory exists\n",
    "# output_dir = 'data/derivedData'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Set the generator to evaluation mode\n",
    "# netG.eval()\n",
    "\n",
    "# # Generate new images\n",
    "# num_images = 100  # Adjust as needed\n",
    "# batch_size = 16\n",
    "# nz = 100  # Size of the latent vector\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i in range(0, num_images, batch_size):\n",
    "#         current_batch_size = min(batch_size, num_images - i)\n",
    "#         noise = torch.randn(current_batch_size, nz, 1, 1, device=device)\n",
    "#         fake_images = netG(noise).detach().cpu()\n",
    "#         for j in range(current_batch_size):\n",
    "#             image_path = os.path.join(output_dir, f\"design_{i + j + 1}.png\")\n",
    "#             save_image(fake_images[j], image_path, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10c13c-9600-41a9-b0cb-907f64eb4278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
